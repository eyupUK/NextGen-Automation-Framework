name: Performance Tests

on:
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of performance test'
        required: true
        default: 'load'
        type: choice
        options: [load, stress, spike]
      users:
        description: 'Number of concurrent users'
        required: false
        default: '10'
      duration:
        description: 'Test duration in seconds'
        required: false
        default: '60'
      simulation:
        description: 'Simulation to run'
        required: true
        default: 'weather'
        type: choice
        options: [weather, ecommerce, all]

  push:
    branches: [ wip, complete-ci-implementation ]

permissions:
  contents: read
  issues: write
  pull-requests: write

concurrency:
  group: performance-tests-${{ github.ref }}
  cancel-in-progress: true

jobs:
  gatling-performance-tests:
    name: Gatling Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45

    env:
      WEATHER_API_KEY: ${{ secrets.WEATHER_API_KEY }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Java 21 (build)
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: 'maven'

      - name: Cache Maven dependencies
        uses: actions/cache@v4
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-

      - name: Install dependencies (no tests)
        run: mvn -B -ntp -s .mvn/ci-settings.xml clean install -DskipTests

      - name: Set up Java 17 (Gatling)
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'temurin'

      - name: Recompile tests for JDK 17 (Gatling)
        run: |
          mvn -B -ntp -s .mvn/ci-settings.xml clean test-compile \
            -Denforcer.skip=true \
            -DWEATHER_API_KEY="${WEATHER_API_KEY}" \
            -DskipTests \
            -Dmaven.compiler.testRelease=17

      - name: Set test parameters
        id: test-params
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "TEST_TYPE=${{ github.event.inputs.test_type }}" >> $GITHUB_ENV
            echo "USERS=${{ github.event.inputs.users }}" >> $GITHUB_ENV
            echo "DURATION=${{ github.event.inputs.duration }}" >> $GITHUB_ENV
            echo "SIMULATION=${{ github.event.inputs.simulation }}" >> $GITHUB_ENV
          else
            echo "TEST_TYPE=load" >> $GITHUB_ENV
            echo "USERS=10" >> $GITHUB_ENV
            echo "DURATION=60" >> $GITHUB_ENV
            echo "SIMULATION=weather" >> $GITHUB_ENV
          fi

      - name: Run Weather API Performance Test
        id: weather-perf
        if: env.SIMULATION == 'weather' || env.SIMULATION == 'all'
        run: |
          set +e
          mvn -B -ntp -s .mvn/ci-settings.xml gatling:test \
            -Denforcer.skip=true \
            -DWEATHER_API_KEY="${WEATHER_API_KEY}" \
            -Dgatling.simulationClass=com.example.performance.gatling.simulations.WeatherApiPerformanceSimulation \
            -Dperf.users=${{ env.USERS }} \
            -Dperf.duration=${{ env.DURATION }} \
            -Dperf.type=${{ env.TEST_TYPE }}
          code=$?
          echo "exitcode=$code" >> "$GITHUB_OUTPUT"
          exit 0

      - name: Run E-commerce API Performance Test
        id: ecommerce-perf
        if: env.SIMULATION == 'ecommerce' || env.SIMULATION == 'all'
        run: |
          set +e
          mvn -B -ntp -s .mvn/ci-settings.xml gatling:test \
            -Denforcer.skip=true \
            -Dgatling.simulationClass=com.example.performance.gatling.simulations.EcommerceApiPerformanceSimulation \
            -Dperf.users=${{ env.USERS }}
          code=$?
          echo "exitcode=$code" >> "$GITHUB_OUTPUT"
          exit 0

      - name: Debug - List target contents (Gatling)
        if: always()
        run: |
          echo "Listing target directory (if exists):" && ls -la target || true
          echo "\nGatling directories:" && ls -la target/gatling-results 2>/dev/null || true
          echo "\nAllure results:" && ls -la target/allure-results 2>/dev/null || true

      - name: Upload Gatling Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: gatling-reports-${{ github.run_number }}
          path: target/gatling-results/
          retention-days: 30

      - name: Generate Performance Summary
        if: always()
        run: |
          echo "# 📊 Performance Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Test Configuration:**" >> $GITHUB_STEP_SUMMARY
          echo "- Test Type: ${{ env.TEST_TYPE }}" >> $GITHUB_STEP_SUMMARY
          echo "- Users: ${{ env.USERS }}" >> $GITHUB_STEP_SUMMARY
          echo "- Duration: ${{ env.DURATION }}s" >> $GITHUB_STEP_SUMMARY
          echo "- Simulation: ${{ env.SIMULATION }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Reports Generated:**" >> $GITHUB_STEP_SUMMARY
          echo "- Download artifacts to view detailed Gatling HTML reports" >> $GITHUB_STEP_SUMMARY
          echo "- Reports include: Response times, throughput, percentiles, charts" >> $GITHUB_STEP_SUMMARY

      - name: Finalize job status (Gatling)
        if: always()
        run: |
          W_CODE='${{ steps.weather-perf.outputs.exitcode }}'
          E_CODE='${{ steps.ecommerce-perf.outputs.exitcode }}'
          [ -z "$W_CODE" ] && W_CODE=0
          [ -z "$E_CODE" ] && E_CODE=0
          if [ "$W_CODE" != "0" ] || [ "$E_CODE" != "0" ]; then
            echo "Gatling run failed. Failing job." && exit 1
          fi

  junit-performance-tests:
    name: JUnit Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      WEATHER_API_KEY: ${{ secrets.WEATHER_API_KEY }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Java
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: 'maven'

      - name: Cache Maven dependencies
        uses: actions/cache@v4
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-

      - name: Install dependencies
        run: mvn -B -ntp -s .mvn/ci-settings.xml clean install -DskipTests

      - name: Prepare performance results folder
        run: mkdir -p target/performance-results

      - name: Run JUnit Performance Tests
        id: junit-perf
        run: |
          set +e
          mvn -B -ntp -s .mvn/ci-settings.xml test -DWEATHER_API_KEY="${WEATHER_API_KEY}" -Dtest=WeatherApiPerformanceTest -Dsla.p95.ms=2000 -Dsla.p99.ms=4000 -Dsla.successRate=95
          code=$?
          echo "exitcode=$code" >> "$GITHUB_OUTPUT"
          exit 0

      - name: Debug - List target contents (JUnit)
        if: always()
        run: |
          echo "Listing target directory (if exists):" && ls -la target || true
          echo "\nSurefire reports:" && ls -la target/surefire-reports 2>/dev/null || true
          echo "\nPerformance results:" && ls -la target/performance-results 2>/dev/null || true

      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: junit-performance-results-${{ github.run_number }}
          path: |
            target/surefire-reports/
            target/performance-results/
          retention-days: 30

      - name: Upload CSV Metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-metrics-csv-${{ github.run_number }}
          path: target/performance-results/*.csv
          retention-days: 90

      - name: Suite Summary - JUnit Performance
        if: always()
        run: |
          echo "# 🧪 Suite Summary - JUnit Performance" >> $GITHUB_STEP_SUMMARY
          echo "Result: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "Artifacts: junit-performance-results-${{ github.run_number }}, performance-metrics-csv-${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY

      - name: Finalize job status (JUnit)
        if: always()
        run: |
          CODE='${{ steps.junit-perf.outputs.exitcode }}'
          [ -z "$CODE" ] && CODE=0
          if [ "$CODE" != "0" ]; then
            echo "JUnit performance run failed. Failing job." && exit 1
          fi

  performance-comparison:
    name: Performance Comparison
    runs-on: ubuntu-latest
    needs: [gatling-performance-tests, junit-performance-tests]
    if: always()
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download Current Gatling Results
        uses: actions/download-artifact@v4
        with:
          name: gatling-reports-${{ github.run_number }}
          path: current-results/

      - name: Download JUnit CSV Metrics
        uses: actions/download-artifact@v4
        with:
          name: performance-metrics-csv-${{ github.run_number }}
          path: junit-csv/

      - name: Generate Comparison Report
        run: |
          set +e
          # Install jq for JSON parsing (used for Gatling stats)
          sudo apt-get update -y >/dev/null 2>&1 && sudo apt-get install -y jq >/dev/null 2>&1 || true

          echo "# 📈 Performance Comparison Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Information:**" >> $GITHUB_STEP_SUMMARY
          echo "- Run Number: #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "- Triggered by: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- Branch: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # SLA thresholds (align with JUnit job)
          P95_SLA=2000
          P99_SLA=4000
          SRATE_SLA=95

          ############################
          # Parse Gatling latest run #
          ############################
          G_TOTAL=""; G_OK=""; G_KO=""; G_MEAN=""; G_P95=""; G_P99=""; G_MAX=""; G_RPS=""; G_SRATE=""; G_DIR=""
          if [ -d current-results ]; then
            G_DIR=$(ls -1dt current-results/*/ 2>/dev/null | head -n 1)
            if [ -n "$G_DIR" ]; then
              if [ -f "$G_DIR/js/stats.json" ]; then
                JSON_FILE="$G_DIR/js/stats.json"
                G_TOTAL=$(jq -r '.stats.numberOfRequests.total' "$JSON_FILE")
                G_OK=$(jq -r '.stats.numberOfRequests.ok' "$JSON_FILE")
                G_KO=$(jq -r '.stats.numberOfRequests.ko' "$JSON_FILE")
                G_MEAN=$(jq -r '.stats.meanResponseTime.total' "$JSON_FILE")
                G_P95=$(jq -r '.stats.percentiles3.total' "$JSON_FILE")
                G_P99=$(jq -r '.stats.percentiles4.total' "$JSON_FILE")
                G_MAX=$(jq -r '.stats.maxResponseTime.total' "$JSON_FILE")
                G_RPS=$(jq -r '.stats.meanNumberOfRequestsPerSecond.total' "$JSON_FILE")
              elif [ -f "$G_DIR/js/stats.js" ]; then
                JSON=$(sed -e '1s/var stats = //' -e '$s/;[[:space:]]*$//' "$G_DIR/js/stats.js" 2>/dev/null)
                if command -v jq >/dev/null 2>&1 && [ -n "$JSON" ]; then
                  G_TOTAL=$(echo "$JSON" | jq -r '.stats.numberOfRequests.total')
                  G_OK=$(echo "$JSON" | jq -r '.stats.numberOfRequests.ok')
                  G_KO=$(echo "$JSON" | jq -r '.stats.numberOfRequests.ko')
                  G_MEAN=$(echo "$JSON" | jq -r '.stats.meanResponseTime.total')
                  G_P95=$(echo "$JSON" | jq -r '.stats.percentiles3.total')
                  G_P99=$(echo "$JSON" | jq -r '.stats.percentiles4.total')
                  G_MAX=$(echo "$JSON" | jq -r '.stats.maxResponseTime.total')
                  G_RPS=$(echo "$JSON" | jq -r '.stats.meanNumberOfRequestsPerSecond.total')
                fi
              fi
            fi
          fi
          if [ -n "$G_TOTAL" ] && [ "$G_TOTAL" != "null" ] && [ "$G_TOTAL" != "" ]; then
            G_SRATE=$(awk -v ok="$G_OK" -v total="$G_TOTAL" 'BEGIN{ if (total>0) printf "%.2f", (ok*100.0)/total; else print "0.00" }')
          fi

          ########################
          # Parse JUnit CSV metrics
          ########################
          J_NAME=""; J_TOTAL=""; J_SUCCESS=""; J_ERRORS=""; J_ERRRATE=""; J_MEAN=""; J_MEDIAN=""; J_P95=""; J_P99=""; J_MAX=""; J_ACTIVE=""; J_SRATE=""
          if ls -1 junit-csv/*.csv >/dev/null 2>&1; then
            CSV_FILE=$(ls -1 junit-csv/*.csv | head -n 1)
            # Skip header and read values
            IFS=',' read -r J_NAME J_TOTAL J_SUCCESS J_ERRORS J_ERRRATE J_MEAN J_MEDIAN J_P95 J_P99 J_MAX J_ACTIVE < <(tail -n +2 "$CSV_FILE")
            if [ -n "$J_TOTAL" ] && [ -n "$J_SUCCESS" ]; then
              J_SRATE=$(awk -v ok="$J_SUCCESS" -v total="$J_TOTAL" 'BEGIN{ if (total>0) printf "%.2f", (ok*100.0)/total; else print "0.00" }')
            fi
          fi

          ########################
          # Write report to summary
          ########################
          echo "**SLA Thresholds:**" >> $GITHUB_STEP_SUMMARY
          echo "- P95 <= ${P95_SLA} ms, P99 <= ${P99_SLA} ms, Success Rate >= ${SRATE_SLA}%" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "## Gatling Summary" >> $GITHUB_STEP_SUMMARY
          if [ -n "$G_TOTAL" ]; then
            echo "- Results dir: ${G_DIR:-n/a}" >> $GITHUB_STEP_SUMMARY
            echo "- Requests: total=${G_TOTAL}, ok=${G_OK:-0}, ko=${G_KO:-0}" >> $GITHUB_STEP_SUMMARY
            echo "- Success Rate: ${G_SRATE:-n/a}%" >> $GITHUB_STEP_SUMMARY
            echo "- Mean: ${G_MEAN:-n/a} ms, P95: ${G_P95:-n/a} ms, P99: ${G_P99:-n/a} ms, Max: ${G_MAX:-n/a} ms" >> $GITHUB_STEP_SUMMARY
            echo "- Mean RPS: ${G_RPS:-n/a}" >> $GITHUB_STEP_SUMMARY
            G_SLA=$(awk -v p95="${G_P95:-0}" -v p99="${G_P99:-0}" -v srate="${G_SRATE:-0}" -v P95="${P95_SLA}" -v P99="${P99_SLA}" -v S="${SRATE_SLA}" 'BEGIN{ if (p95!="" && p99!="" && srate!="" && p95<=P95 && p99<=P99 && srate>=S) print "Yes"; else print "No" }')
            echo "- SLA met: ${G_SLA}" >> $GITHUB_STEP_SUMMARY
          else
            echo "- No Gatling results found in artifacts." >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## JUnit Summary" >> $GITHUB_STEP_SUMMARY
          if [ -n "$J_TOTAL" ]; then
            echo "- CSV: ${CSV_FILE:-n/a}" >> $GITHUB_STEP_SUMMARY
            echo "- Name: ${J_NAME}" >> $GITHUB_STEP_SUMMARY
            echo "- Requests: total=${J_TOTAL}, ok=${J_SUCCESS:-0}, errors=${J_ERRORS:-0} (errorRate=${J_ERRRATE:-n/a}%)" >> $GITHUB_STEP_SUMMARY
            echo "- Success Rate: ${J_SRATE:-n/a}%" >> $GITHUB_STEP_SUMMARY
            echo "- Mean: ${J_MEAN:-n/a} ms, Median: ${J_MEDIAN:-n/a} ms, P95: ${J_P95:-n/a} ms, P99: ${J_P99:-n/a} ms, Max: ${J_MAX:-n/a} ms" >> $GITHUB_STEP_SUMMARY
            J_SLA=$(awk -v p95="${J_P95:-0}" -v p99="${J_P99:-0}" -v srate="${J_SRATE:-0}" -v P95="${P95_SLA}" -v P99="${P99_SLA}" -v S="${SRATE_SLA}" 'BEGIN{ if (p95!="" && p99!="" && srate!="" && p95<=P95 && p99<=P99 && srate>=S) print "Yes"; else print "No" }')
            echo "- SLA met: ${J_SLA}" >> $GITHUB_STEP_SUMMARY
          else
            echo "- No JUnit CSV metrics found in artifacts." >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Overall Verdict" >> $GITHUB_STEP_SUMMARY
          if [ "${G_SLA}" = "Yes" ] && [ "${J_SLA}" = "Yes" ]; then
            echo "Both Gatling and JUnit performance met the configured SLAs." >> $GITHUB_STEP_SUMMARY
          elif [ "${G_SLA}" = "Yes" ] || [ "${J_SLA}" = "Yes" ]; then
            echo "Partial pass: At least one suite met SLAs. Review the failing suite's metrics above." >> $GITHUB_STEP_SUMMARY
          else
            echo "SLAs not met by either suite. Investigate regressions and bottlenecks." >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Artifacts Available:**" >> $GITHUB_STEP_SUMMARY
          echo "- 📊 Gatling HTML Reports (interactive charts)" >> $GITHUB_STEP_SUMMARY
          echo "- 📈 CSV Metrics (for trend analysis)" >> $GITHUB_STEP_SUMMARY
          echo "- 📝 Test Results (detailed logs)" >> $GITHUB_STEP_SUMMARY
